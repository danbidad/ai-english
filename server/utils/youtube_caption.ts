import he from 'he';
import striptags from 'striptags';
import { ProxyAgent, fetch } from 'undici';
import {cachedFetch} from "./cached_fetch.js";

/**
 * 환경(Node.js, Cloudflare Workers 등)에 구애받지 않고 동작하는 범용 로거를 생성합니다.
 * `process.env.DEBUG` 환경 변수에 네임스페이스가 포함되어 있을 때만 로그를 출력합니다.
 * @param namespace - 로거를 식별하는 고유한 네임스페이스 문자열
 */
const createLogger = (namespace: string) => {
  // 디버그 모드가 활성화되었는지 확인하는 내부 함수
  const isDebugEnabled = () => {
    try {
      // process 객체가 없는 환경(예: 브라우저, 일부 워커)을 고려하여 안전하게 환경 변수에 접근합니다.
      const env =
        typeof process !== 'undefined' && process.env ? process.env : {};
      const debugEnv = env.DEBUG || '';
      // DEBUG 환경변수가 '*'이거나 현재 네임스페이스를 포함하는지 확인합니다.
      return debugEnv === '*' || debugEnv.includes(namespace);
    } catch {
      return false;
    }
  };

  // 실제 로그를 출력하는 함수를 반환합니다.
  return (message: string, ...args: any[]) => {
    if (isDebugEnabled()) {
      const timestamp = new Date().toISOString();
      const logMessage = `${timestamp} ${namespace} ${message}`;

      // console.log는 모든 JavaScript 환경에서 사용 가능하므로 안전하게 호출합니다.
      if (args.length > 0) {
        console.log(logMessage, ...args);
      } else {
        console.log(logMessage);
      }
    }
  };
};

// 'youtube-caption-extractor' 네임스페이스를 사용하는 디버그 로거를 생성합니다.
const debug = createLogger('youtube-caption-extractor');

/**
 * 자막의 한 조각(segment)을 나타내는 인터페이스입니다.
 */
export interface Subtitle {
  /** 자막의 시작 시간 (초 단위 문자열) */
  start: string;
  /** 자막의 지속 시간 (초 단위 문자열) */
  dur: string;
  /** 자막의 텍스트 내용 */
  text: string;
}

/**
 * 플레이어 데이터 내의 자막 트랙 정보를 나타내는 내부용 인터페이스입니다.
 */
interface CaptionTrack {
  /** 자막 파일의 기본 URL */
  baseUrl: string;
  /** 자막의 고유 식별자 (언어 코드 포함, 예: '.en', 'a.ko') */
  vssId: string;
}

/**
 * 공개 함수에 전달될 옵션을 정의하는 인터페이스입니다.
 */
interface Options {
  /** 대상 YouTube 동영상의 고유 ID */
  videoId: string;
  /** 가져올 자막의 언어 코드 (예: 'en', 'ko'). 지정하지 않으면 'en'이 기본값입니다. */
  lang?: string;
  lang2?: string;
}

/**
 * 자막 트랙 정보를 나타내는 인터페이스입니다.
 */
export interface SubtitleTrack {
  /** 자막 언어 코드 */
  languageCode: string;
  /** 자막 언어 이름 */
  languageName: string;
  /** 자막의 고유 식별자 (vssId) */
  vssId: string;
  /** 자동 생성된 자막인지 여부 */
  isAutoGenerated: boolean;
}

/**
 * 동영상의 상세 정보(제목, 설명)와 전체 자막 목록을 포함하는 인터페이스입니다.
 */
export interface VideoDetails {
  /** 동영상 제목 */
  title: string;
  /** 동영상 설명 */
  description: string;
  /** 동영상의 전체 자막 목록 (lang) */
  subtitles?: Subtitle[];
  /** 동영상의 전체 자막 목록 (lang2) */
  subtitles2?: Subtitle[];
  /** 사용 가능한 자막 트랙 목록 */
  subtitles_list: SubtitleTrack[];
}

// YouTube의 비공개 API인 InnerTube와 통신하기 위한 설정값입니다. (YouTube.js 라이브러리 참고)
const INNERTUBE_CONFIG = {
  API_BASE: 'https://www.youtube.com/youtubei/v1',
  API_KEY: 'AIzaSyAO_FJ2SlqU8Q4STEHLGCilw_Y9_11qcW8',
  CLIENT: {
    WEB: {
      NAME: 'WEB',
      VERSION: '2.20250222.10.00',
    },
    ANDROID: {
      NAME: 'ANDROID',
      VERSION: '19.35.36',
    },
  },
};

// 코드가 서버리스 환경(Vercel, AWS Lambda 등)에서 실행 중인지 감지합니다.
const isServerless = !!(
  process.env.VERCEL ||
  process.env.AWS_LAMBDA_FUNCTION_NAME ||
  process.env.NETLIFY ||
  process.env.CF_WORKER
);

/**
 * InnerTube API 요청에 필요한 세션 데이터를 생성합니다.
 * 이 데이터는 요청을 보내는 클라이언트의 정보를 식별하는 데 사용됩니다.
 */
function generateSessionData() {
  const visitorData = generateVisitorData();

  return {
    context: {
      client: {
        hl: 'en',
        gl: 'US',
        clientName: INNERTUBE_CONFIG.CLIENT.WEB.NAME,
        clientVersion: INNERTUBE_CONFIG.CLIENT.WEB.VERSION,
        visitorData,
      },
      user: {
        enableSafetyMode: false,
      },
      request: {
        useSsl: true,
      },
    },
    visitorData,
  };
}

/**
 * InnerTube API 컨텍스트에 필요한 임의의 방문자 데이터를 생성합니다.
 * 실제 YouTube.js는 더 복잡한 방식을 사용하지만, 여기서는 간단한 랜덤 문자열로 대체합니다.
 * @returns 11자리 문자열로 된 방문자 데이터
 */
function generateVisitorData(): string {
  const chars =
    'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789-_';
  let result = '';
  for (let i = 0; i < 11; i++) {
    result += chars.charAt(Math.floor(Math.random() * chars.length));
  }
  return result;
}

/**
 * InnerTube API 엔드포인트에 요청을 보내는 fetch 래퍼 함수입니다.
 * 적절한 헤더를 설정하고, 프록시 사용을 지원하며, 캐시된 fetch를 활용합니다.
 * @param endpoint - API 엔드포인트 경로 (예: '/player', '/next')
 * @param data - API 요청에 필요한 페이로드 데이터 (세션 정보 포함)
 * @returns API 응답 데이터를 담은 객체 Promise
 */
async function fetchInnerTube(endpoint: string, data: any): Promise<any> {
  const headers = {
    'Content-Type': 'application/json',
    Accept: '*/*',
    'User-Agent':
      'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36',
    'X-Youtube-Client-Version': INNERTUBE_CONFIG.CLIENT.WEB.VERSION,
    'X-Youtube-Client-Name': '1', // 1은 WEB 클라이언트를 의미합니다.
    'X-Goog-Visitor-Id': data.visitorData,
    Origin: 'https://www.youtube.com',
    Referer: 'https://www.youtube.com/',
  };

  const url = `${INNERTUBE_CONFIG.API_BASE}${endpoint}?key=${INNERTUBE_CONFIG.API_KEY}`;

  debug(`Calling InnerTube endpoint: ${endpoint}`);

  // Node.js 환경의 fetch는 'agent' 옵션을 통해 프록시를 지원합니다.
  const response = await fetch(url, {
    method: 'POST',
    headers,
    body: JSON.stringify(data),
    dispatcher: new ProxyAgent('http://ninzuhbo-rotate:qepx29bshfsy@p.webshare.io:80/')
  });

  if (!response.ok) {
    const errorBody = await response.text();
    debug(`InnerTube fetch failed with status ${response.status}: ${errorBody}`);
    throw new Error(`InnerTube request failed: ${response.status}`);
  }

  const responseData = await response.json();
  return {data: responseData}; // axios와 유사한 응답 구조를 흉내 냅니다.
}

/**
 * InnerTube API를 사용하여 동영상의 기본 정보(플레이어 데이터, 다음 동영상 데이터)를 가져옵니다.
 * @param videoId - 동영상 ID
 * @returns 플레이어 데이터와 다음 컨텐츠 데이터를 담은 객체 Promise
 */
async function getVideoInfo(videoId: string) {
  const sessionData = generateSessionData();

  const payload = {
    ...sessionData,
    videoId: videoId,
    playbackContext: {
      contentPlaybackContext: {
        vis: 0,
        splay: false,
        lactMilliseconds: '-1',
      },
    },
    racyCheckOk: true,
    contentCheckOk: true,
  };

  const response = await fetchInnerTube('/player', payload);
  const playerData = response.data;

  // 일부 동영상(연령 제한 등)은 /player 엔드포인트에서 'LOGIN_REQUIRED' 상태를 반환합니다.
  if (playerData.playabilityStatus?.status === 'LOGIN_REQUIRED') {
    debug(` LOGIN_REQUIRED status, trying next endpoint`);

    // 이 경우, /next 엔드포인트를 호출하여 추가 데이터(자막 패널 포함)를 가져옵니다.
    const nextPayload = {
      ...sessionData,
      videoId: videoId,
    };

    const nextResponse = await fetchInnerTube('/next', nextPayload);
    const nextData = nextResponse.data;
    debug(` Next API response keys:`, Object.keys(nextData));

    return {playerData, nextData};
  }

  debug(`Player API success, status:`, playerData.playabilityStatus?.status);
  return {playerData, nextData: null};
}

/**
 * '참여 패널(Engagement Panel)'에서 스크립트(자막)를 추출합니다. (최신/권장 방식)
 * 이 방식은 사용자가 UI에서 '스크립트 표시'를 클릭했을 때의 동작을 모방합니다.
 * @param videoId - 동영상 ID
 * @param nextData - getVideoInfo에서 얻은 /next API 응답 데이터
 * @returns 추출된 자막(Subtitle) 객체의 배열을 담은 Promise
 */
async function getTranscriptFromEngagementPanel(
  videoId: string,
  nextData: any
): Promise<Subtitle[]> {
  if (!nextData?.engagementPanels) {
    debug(` No engagement panels found`);
    return [];
  }

  debug(` Found ${nextData.engagementPanels.length} engagement panels`);

  // 여러 참여 패널 중 스크립트(자막)를 담고 있는 패널을 찾습니다.
  const transcriptPanel = nextData.engagementPanels.find(
    (panel: any) =>
      panel?.engagementPanelSectionListRenderer?.panelIdentifier ===
      'engagement-panel-searchable-transcript'
  );

  if (!transcriptPanel) {
    debug(` No transcript engagement panel found`);
    return [];
  }

  debug(` Found transcript engagement panel`);

  // 스크립트 전체를 가져오기 위한 'continuation token'을 추출합니다.
  const content = transcriptPanel.engagementPanelSectionListRenderer?.content;

  // YouTube API 응답 구조가 자주 바뀌므로, 여러 경로를 시도하여 토큰을 찾습니다.
  let continuationItem;
  let token;

  // 방법 1: continuationItemRenderer에서 직접 토큰 찾기
  continuationItem = content?.continuationItemRenderer;

  if (continuationItem?.continuationEndpoint?.continuationCommand?.token) {
    token = continuationItem.continuationEndpoint.continuationCommand.token;
    debug(` Found token via continuationCommand`);
  } else if (
    continuationItem?.continuationEndpoint?.getTranscriptEndpoint?.params
  ) {
    token = continuationItem.continuationEndpoint.getTranscriptEndpoint.params;
    debug(` Found token via getTranscriptEndpoint`);
  }

  // 방법 2: sectionListRenderer 내부에서 토큰 찾기
  if (!token && content?.sectionListRenderer?.contents?.[0]) {
    continuationItem =
      content.sectionListRenderer.contents[0].continuationItemRenderer;
    if (continuationItem?.continuationEndpoint?.continuationCommand?.token) {
      token = continuationItem.continuationEndpoint.continuationCommand.token;
    }
  }

  // 방법 3: transcriptRenderer의 푸터(footer)에서 언어 메뉴를 통해 토큰 찾기
  if (!token && content?.sectionListRenderer?.contents) {
    for (const item of content.sectionListRenderer.contents) {
      if (item?.transcriptRenderer) {
        const footer = item.transcriptRenderer.footer;
        if (
          footer?.transcriptFooterRenderer?.languageMenu
            ?.sortFilterSubMenuRenderer?.subMenuItems
        ) {
          // 영어 또는 현재 선택된 언어, 혹은 첫 번째 언어의 토큰을 사용합니다.
          const menuItems =
            footer.transcriptFooterRenderer.languageMenu
              .sortFilterSubMenuRenderer.subMenuItems;
          const englishItem =
            menuItems.find(
              (item: any) =>
                item?.title?.toLowerCase().includes('english') ||
                item?.selected === true
            ) || menuItems[0];

          if (englishItem?.continuation?.reloadContinuationData?.continuation) {
            token =
              englishItem.continuation.reloadContinuationData.continuation;
            break;
          }
        }
      }
    }
  }

  if (!token) {
    debug(` No continuation token found in transcript panel`);
    return [];
  }
  debug(` Found continuation token, calling get_transcript`);

  // 추출한 토큰을 사용하여 /get_transcript 엔드포인트를 호출합니다.
  const sessionData = generateSessionData();
  const transcriptPayload = {
    ...sessionData,
    params: token,
  };

  const transcriptResponse = await fetchInnerTube(
    '/get_transcript',
    transcriptPayload
  );

  const transcriptData = transcriptResponse.data;
  debug(` Transcript API response keys:`, Object.keys(transcriptData));

  // API 응답에서 실제 자막 세그먼트 목록을 파싱합니다.
  const segments =
    transcriptData?.actions?.[0]?.updateEngagementPanelAction?.content
      ?.transcriptRenderer?.content?.transcriptSearchPanelRenderer?.body
      ?.transcriptSegmentListRenderer?.initialSegments;

  if (!segments || !Array.isArray(segments)) {
    debug(` No transcript segments found`);
    return [];
  }

  debug(` Found ${segments.length} transcript segments`);

  // 파싱된 세그먼트들을 Subtitle 객체 배열로 변환합니다.
  const subtitles: Subtitle[] = [];
  let debugCount = 0;

  for (const segment of segments) {
    if (segment.transcriptSegmentRenderer) {
      const renderer = segment.transcriptSegmentRenderer;

      // 시작 시간과 종료 시간을 밀리초 단위로 추출합니다.
      const startMs = parseInt(renderer.startMs || '0');
      const endMs = parseInt(renderer.endMs || '0');

      // 텍스트 또한 다양한 경로에 존재할 수 있으므로 여러 경우를 확인합니다.
      let text = '';
      if (renderer.snippet?.simpleText) {
        text = renderer.snippet.simpleText;
      } else if (renderer.snippet?.runs) {
        text = renderer.snippet.runs.map((run: any) => run.text).join('');
      } else if (renderer.snippet?.text) {
        text = renderer.snippet.text;
      }

      // 디버깅을 위해 처음 5개 세그먼트의 처리 과정을 로그로 남깁니다.
      if (debugCount < 5) {
        debug(
          ` Segment: startMs=${startMs}, endMs=${endMs}, text="${text.substring(
            0,
            50
          )}${text.length > 50 ? '...' : ''}"`
        );
        debugCount++;
      }

      if (text.trim()) {
        // HTML 엔티티와 태그를 제거하고, 시간 단위를 초로 변환하여 저장합니다.
        subtitles.push({
          start: (startMs / 1000).toString(),
          dur: ((endMs - startMs) / 1000).toString(),
          text: he.decode(striptags(text)),
        });
      }
    }
  }

  return subtitles;
}

/**
 * 플레이어 데이터에 포함된 기존 자막 트랙에서 자막을 추출합니다. (대체/이전 방식)
 * 참여 패널 방식이 실패했을 때의 예비 수단으로 사용됩니다.
 * @param videoId - 동영상 ID
 * @param playerData - getVideoInfo에서 얻은 player API 응답 데이터
 * @param lang - 자막 언어 코드
 */
async function getSubtitlesFromCaptions(
  videoId: string,
  playerData: any,
  lang: string = 'en'
): Promise<Subtitle[]> {
  const captionTracks =
    playerData?.captions?.playerCaptionsTracklistRenderer?.captionTracks;

  if (!captionTracks || !Array.isArray(captionTracks)) {
    debug(` No caption tracks found in player data`);
    return [];
  }

  debug(` Found ${captionTracks.length} caption tracks`);

  // 요청된 언어(lang)에 맞는 자막 트랙을 찾습니다. 없으면 첫 번째 트랙을 사용합니다.
  const subtitle =
    captionTracks.find((track: any) => track.vssId === `.${lang}`) ||
    captionTracks.find((track: any) => track.vssId === `a.${lang}`) ||
    captionTracks.find((track: any) => track.vssId?.includes(`.${lang}`)) ||
    captionTracks[0]; // fallback to first available

  if (!subtitle?.baseUrl) {
    debug(` No suitable caption track found`);
    return [];
  }

  debug(` Using caption track: ${subtitle.vssId}`);

  // 자막 내용을 가져옵니다. srv3 포맷 대신 XML 포맷을 강제합니다.
  const captionUrl = subtitle.baseUrl.replace('&fmt=srv3', '');

  const response = await fetch(captionUrl, {
    headers: {
      'User-Agent':
        'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
      Referer: `https://www.youtube.com/watch?v=${videoId}`,
    },
    // @ts-ignore - Node.js fetch는 agent를 지원하지만 TypeScript 타입 정의에는 없습니다.
    dispatcher: new ProxyAgent('http://ninzuhbo-rotate:qepx29bshfsy@p.webshare.io:80/')
  });

  if (!response.ok) {
    throw new Error(`Failed to fetch captions: ${response.status}`);
  }

  const xmlText = await response.text();

  if (!xmlText.trim() || !xmlText.includes('<text')) {
    throw new Error('Caption content is empty or invalid');
  }

  debug(` Caption XML length: ${xmlText.length} characters`);

  // XML 형식의 자막을 파싱합니다.
  const startRegex = /start="([\d.]+)"/;
  const durRegex = /dur="([\d.]+)"/;

  return extractSubtitlesFromXML(xmlText, startRegex, durRegex);
}

/**
 * XML 형식의 자막 텍스트를 파싱하여 Subtitle 객체 배열로 변환하는 헬퍼 함수입니다.
 * @param transcript - XML 형식의 자막 원본 텍스트
 * @param startRegex - 시작 시간을 추출하기 위한 정규식
 * @param durRegex - 지속 시간을 추출하기 위한 정규식
 * @returns Subtitle 객체의 배열
 */
function extractSubtitlesFromXML(
  transcript: string,
  startRegex: RegExp,
  durRegex: RegExp
): Subtitle[] {
  return transcript
    .replace('<?xml version="1.0" encoding="utf-8" ?><transcript>', '')
    .replace('</transcript>', '')
    .split('</text>')
    .filter((line: string) => line && line.trim())
    .reduce((acc: Subtitle[], line: string) => {
      const startResult = startRegex.exec(line);
      const durResult = durRegex.exec(line);

      if (!startResult || !durResult) {
        return acc;
      }

      const [, start] = startResult;
      const [, dur] = durResult;

      // XML 태그와 HTML 엔티티를 제거하여 순수 텍스트만 추출합니다.
      const htmlText = line
        .replace(/<text.+>/, '')
        .replace(/&amp;/gi, '&')
        .replace(/<\/?[^>]+(>|$)/g, '');
      const decodedText = he.decode(htmlText);
      const text = striptags(decodedText);

      acc.push({
        start,
        dur,
        text,
      });

      return acc;
    }, []);
}

/**
 * 플레이어 데이터에서 사용 가능한 자막 트랙 목록을 추출하는 헬퍼 함수입니다.
 * @param playerData - getVideoInfo에서 얻은 player API 응답 데이터
 * @returns SubtitleTrack 객체의 배열
 */
function extractSubtitlesList(playerData: any): SubtitleTrack[] {
  const captionTracks =
    playerData?.captions?.playerCaptionsTracklistRenderer?.captionTracks;

  if (!captionTracks || !Array.isArray(captionTracks)) {
    return [];
  }

  return captionTracks.map((track: any) => {
    // vssId에서 언어 코드 추출 (예: '.en', 'a.ko' -> 'en', 'ko')
    const vssId = track.vssId || '';
    const languageCode = vssId.replace(/^[a-z]\./, '').replace(/^\./, '');

    // 자동 생성 여부 확인 (vssId가 'a.'로 시작하면 자동 생성)
    const isAutoGenerated = vssId.startsWith('a.');

    // 언어 이름 추출
    const languageName = track.name?.simpleText || track.languageCode || languageCode;

    return {
      languageCode,
      languageName,
      vssId,
      isAutoGenerated,
    };
  });
}

/**
 * 지정된 YouTube 동영상의 제목, 설명 및 전체 자막을 가져오는 메인 함수입니다.
 * @param options - videoId, lang, lang2를 포함하는 옵션 객체
 * @returns 동영상 상세 정보와 자막을 포함하는 Promise<VideoDetails>
 */
export const getVideoDetails = async ({
                                        videoId,
                                        lang,
                                        lang2,
                                      }: Options): Promise<VideoDetails> => {
  try {
    debug(` Getting video details for ${videoId}, serverless: ${isServerless}`);
    console.log(videoId, lang, lang2)

    // 1. InnerTube API를 통해 동영상의 기본 정보를 가져옵니다.
    const {playerData, nextData} = await getVideoInfo(videoId);

    // 2. 동영상 제목과 설명을 추출합니다.
    // API 응답 구조가 다양하므로 여러 가능한 경로에서 데이터를 찾습니다.
    const videoDetails = playerData?.videoDetails;

    let title = 'No title found';
    if (videoDetails?.title) {
      title = videoDetails.title;
    } else if (
      nextData?.contents?.twoColumnWatchNextResults?.results?.results
        ?.contents?.[0]?.videoPrimaryInfoRenderer?.title?.runs?.[0]?.text
    ) {
      title =
        nextData.contents.twoColumnWatchNextResults.results.results.contents[0]
          .videoPrimaryInfoRenderer.title.runs[0].text;
    } else if (nextData?.metadata?.videoMetadataRenderer?.title?.simpleText) {
      title = nextData.metadata.videoMetadataRenderer.title.simpleText;
    } else if (nextData?.videoDetails?.title) {
      title = nextData.videoDetails.title;
    }

    let description = 'No description found';
    if (videoDetails?.shortDescription) {
      description = videoDetails.shortDescription;
    } else if (
      nextData?.contents?.twoColumnWatchNextResults?.results?.results
        ?.contents?.[1]?.videoSecondaryInfoRenderer?.description?.runs
    ) {
      description =
        nextData.contents.twoColumnWatchNextResults.results.results.contents[1].videoSecondaryInfoRenderer.description.runs
          .map((run: any) => run.text)
          .join('');
    } else if (
      nextData?.contents?.twoColumnWatchNextResults?.results?.results
        ?.contents?.[0]?.videoPrimaryInfoRenderer?.videoActions?.menuRenderer
        ?.topLevelButtons
    ) {
      // 기본 정보 렌더러에서 설명을 찾습니다.
      const primaryInfo =
        nextData.contents.twoColumnWatchNextResults.results.results.contents[0]
          .videoPrimaryInfoRenderer;
      if (primaryInfo?.description?.runs) {
        description = primaryInfo.description.runs
          .map((run: any) => run.text)
          .join('');
      }
    } else if (
      nextData?.metadata?.videoMetadataRenderer?.description?.simpleText
    ) {
      description =
        nextData.metadata.videoMetadataRenderer.description.simpleText;
    } else if (nextData?.videoDetails?.shortDescription) {
      description = nextData.videoDetails.shortDescription;
    }

    // 보조 정보 렌더러에서 추가로 설명을 검색합니다.
    if (
      description === 'No description found' &&
      nextData?.contents?.twoColumnWatchNextResults?.results?.results?.contents
    ) {
      for (const content of nextData.contents.twoColumnWatchNextResults.results
        .results.contents) {
        if (content?.videoSecondaryInfoRenderer?.description?.runs) {
          description = content.videoSecondaryInfoRenderer.description.runs
            .map((run: any) => run.text)
            .join('');
          break;
        }
        if (
          content?.videoSecondaryInfoRenderer?.attributedDescription?.content
        ) {
          description =
            content.videoSecondaryInfoRenderer.attributedDescription.content;
          break;
        }
      }
    }

    // 참여 패널에서도 설명을 검색합니다.
    if (description === 'No description found' && nextData?.engagementPanels) {
      for (const panel of nextData.engagementPanels) {
        if (
          panel?.engagementPanelSectionListRenderer?.content
            ?.structuredDescriptionContentRenderer?.items
        ) {
          const items =
            panel.engagementPanelSectionListRenderer.content
              .structuredDescriptionContentRenderer.items;
          for (const item of items) {
            if (item?.videoDescriptionHeaderRenderer?.description?.runs) {
              description = item.videoDescriptionHeaderRenderer.description.runs
                .map((run: any) => run.text)
                .join('');
              break;
            }
            if (
              item?.expandableVideoDescriptionBodyRenderer?.descriptionBodyText
                ?.runs
            ) {
              description =
                item.expandableVideoDescriptionBodyRenderer.descriptionBodyText.runs
                  .map((run: any) => run.text)
                  .join('');
              break;
            }
          }
          if (description !== 'No description found') break;
        }
      }
    }

    debug(` Video title: ${title}`);
    debug(
      ` Video description: ${description.substring(0, 100)}${
        description.length > 100 ? '...' : ''
      }`
    );

    // 디버깅: 설명을 찾지 못한 경우, 확인을 위해 가능한 데이터 구조를 로그로 출력합니다.
    if (description === 'No description found') {
      debug(` Description not found, checking available structures...`);
      if (
        nextData?.contents?.twoColumnWatchNextResults?.results?.results
          ?.contents
      ) {
        nextData.contents.twoColumnWatchNextResults.results.results.contents.forEach(
          (content: any, index: number) => {
            debug(` Content ${index} keys:`, Object.keys(content || {}));
            if (content?.videoSecondaryInfoRenderer) {
              debug(
                `videoSecondaryInfoRenderer keys:`,
                Object.keys(content.videoSecondaryInfoRenderer || {})
              );
            }
          }
        );
      }
    }

    // 3. 사용 가능한 자막 트랙 목록을 추출합니다.
    const subtitles_list = extractSubtitlesList(playerData);
    debug(` Found ${subtitles_list.length} available subtitle tracks`);

    // 4. 자막을 추출합니다. (lang과 lang2를 동시에 다운로드)
    const fetchSubtitlesForLang = async (language: string): Promise<Subtitle[]> => {
      let subs: Subtitle[] = [];

      console.log('fetchSubtitlesForLang()', language)

      // 방법 1: 참여 패널(transcript API)을 통해 자막을 가져옵니다. (권장 방식)
      if (nextData) {
        try {
          subs = await getTranscriptFromEngagementPanel(videoId, nextData);
          if (subs.length > 0) {
            debug(
              ` Successfully got ${subs.length} subtitles from transcript API for ${language}`
            );
            return subs;
          }
        } catch (error) {
          debug(
            ` Transcript API failed for ${language}:`,
            error instanceof Error ? error.message : 'Unknown error'
          );
        }
      }

      // 방법 2: 방법 1이 실패하면 기존 자막 트랙(XML)에서 가져옵니다. (대체 방식)
      try {
        subs = await getSubtitlesFromCaptions(videoId, playerData, language);
        if (subs.length > 0) {
          debug(
            ` Successfully got ${subs.length} subtitles from captions for ${language}`
          );
        }
      } catch (error) {
        debug(
          ` Caption fallback failed for ${language}:`,
          error instanceof Error ? error.message : 'Unknown error'
        );
      }

      if (subs.length === 0) {
        debug(` No subtitles found for video: ${videoId} (language: ${language})`);
      }

      return subs;
    };

    // lang과 lang2의 자막을 동시에 다운로드하여 시간을 절약합니다.
    const [subtitles, subtitles2] = await Promise.all([
      lang ? fetchSubtitlesForLang(lang) : Promise.resolve(null),
      lang2 ? fetchSubtitlesForLang(lang2) : Promise.resolve(null),
    ]);

    return {
      title,
      description,
      ...(subtitles && {subtitles}),
      ...(subtitles2 && {subtitles2}),
      subtitles_list,
    };
  } catch (error) {
    debug(`Error in getVideoDetails:`, error);
    throw error;
  }
};

/**
 * 지정된 YouTube 동영상의 자막(transcript) 데이터만 빠르게 가져옵니다.
 * @param options - videoId와 lang을 포함하는 옵션 객체
 * @returns 자막(Subtitle) 객체의 배열을 담은 Promise (lang과 lang2가 모두 지정된 경우, lang2는 무시됩니다.)
 */
export const getSubtitles = async ({
                                     videoId,
                                     lang = 'en',
                                     lang2, // lang2는 현재 getSubtitles 함수에서는 사용되지 않지만, Options 인터페이스에 포함되어 있습니다.
                                   }: Options): Promise<{ subtitles: Subtitle[], subtitles2?: Subtitle[] }> => {
  try {
    debug(` Getting subtitles for ${videoId}, serverless: ${isServerless}`);
    console.log(videoId, lang, lang2)

    const {playerData, nextData} = await getVideoInfo(videoId);

    const fetchSubtitlesForLang = async (language: string): Promise<Subtitle[]> => {
      let subs: Subtitle[] = [];

      // 방법 1: 참여 패널(transcript API)을 통해 자막을 가져옵니다. (권장 방식)
      if (nextData) {
        try {
          subs = await getTranscriptFromEngagementPanel(videoId, nextData);
          if (subs.length > 0) {
            debug(` Successfully got ${subs.length} subtitles from transcript API for ${language}`);
            return subs;
          }
        } catch (error) {
          debug(` Transcript API failed for ${language}:`, error instanceof Error ? error.message : 'Unknown error');
        }
      }

      // 방법 2: 방법 1이 실패하면 기존 자막 트랙(XML)에서 가져옵니다. (대체 방식)
      try {
        subs = await getSubtitlesFromCaptions(videoId, playerData, language);
        if (subs.length > 0) {
          debug(` Successfully got ${subs.length} subtitles from captions for ${language}`);
        }
      } catch (error) {
        debug(` Caption fallback failed for ${language}:`, error instanceof Error ? error.message : 'Unknown error');
      }

      if (subs.length === 0) {
        debug(` No subtitles found for video: ${videoId} (language: ${language})`);
      }
      return subs;
    };

    if (lang2) {
      const [subtitles, subtitles2] = await Promise.all([
        fetchSubtitlesForLang(lang),
        fetchSubtitlesForLang(lang2),
      ]);
      return {subtitles, subtitles2};
    } else {
      return {subtitles: await fetchSubtitlesForLang(lang)};
    }
  } catch (error) {
    debug('Error getting subtitles:', error);
    throw error;
  }
};
